### Literature
This curated list covers the evolution of **Implicit Neural Representations (INRs)** from foundational theory to recent breakthroughs.

### Implicit Neural Representations with Periodic Activation Functions (SIREN)
* **Authors:** Vincent Sitzmann et al.
* **Year:** 2020
* **Summary:** The seminal paper introducing Sinusoidal Representation Networks (SIRENs) to capture high-frequency details and their derivatives using periodic activation functions.
* **Link:** [View Paper](https://arxiv.org/abs/2006.09661)

### Fourier Features Let Networks Learn High-Frequency Functions in Low-Dimensional Domains
* **Authors:** Matthew Tancik et al.
* **Year:** 2020
* **Summary:** Introduces positional encoding techniques to overcome the "spectral bias" that typically prevents standard ReLU networks from learning fine details.
* **Link:** [View Paper](https://arxiv.org/abs/2006.10739)

### Dynamical Implicit Neural Representations (DINR)
* **Authors:** Yesom Park et al.
* **Year:** 2025
* **Summary:** Treats feature evolution as a continuous-time dynamical system rather than a stack of layers to enhance expressivity and mitigate spectral bias.
* **Link:** [View Paper](https://arxiv.org/abs/2511.21787)

### Bilevel Optimized Implicit Neural Representation (OptiINR)
* **Authors:** Hongze Yu et al.
* **Year:** 2025
* **Summary:** Employs Bayesian optimization to automate the search for optimal activation families and initialization parameters across various signal processing tasks.
* **Link:** [View Paper](https://arxiv.org/abs/2502.21292)

### Versatile Neural Processes for Learning Implicit Neural Representations
* **Authors:** Zongyu Guo et al.
* **Year:** 2023
* **Summary:** Proposes an efficient framework for fast inference of continuous functions from partial observations using hierarchical global latent variables.
* **Link:** [View Paper](https://arxiv.org/abs/2301.08883)

### REV-INR: Regularized Evidential Implicit Neural Representation
* **Authors:** Tom Hendriks et al.
* **Year:** 2026
* **Summary:** The first work to quantify both model-level (epistemic) and data-level (aleatoric) uncertainty using a single forward pass of an INR.
* **Link:** [View Paper](https://arxiv.org/abs/2602.04567)

### Uncertainty-Aware Implicit Neural Representations for Volume Visualization
* **Authors:** Dhaval R. Vyas et al.
* **Year:** 2024/2025
* **Summary:** Evaluates Deep Ensembles and Monte Carlo Dropout for estimating trust in reconstructed scalar fields in scientific visualization.
* **Link:** [View Paper](https://www.osti.gov/biblio/2361657)

### Neural Gaussian Force Field (NGFF)
* **Authors:** Wang et al.
* **Year:** 2025/2026
* **Summary:** Introduces a framework that learns explicit force fields from 3D Gaussian representations to generate physically realistic dynamics.
* **Link:** [View Paper](https://arxiv.org/abs/2602.00148)

### Shifted Boundary Method (SBM) Coupled with Neural Implicit Geometries
* **Organization:** National Science Foundation / ResearchGate
* **Year:** 2024
* **Summary:** Directly couples neural implicit geometries with SBM to perform high-fidelity fluid simulations without intermediate mesh generation.
* **Link:** [View Report](https://www.researchgate.net/publication/384968900_SDF-PINNs_Joining_Physics-Informed_Neural_Networks_with_Neural_Implicit_Geometry_Representation)

### A Physics-Informed Neural Network Approach for UAV Path Planning
* **Authors:** Miao et al.
* **Year:** 2025
* **Summary:** Embeds obstacle avoidance and dynamics directly into the learning process using gradient-based barrier potentials (force-fields).
* **Link:** [View Paper](https://www.researchgate.net/publication/396966841_A_Physics-Informed_Neural_Network_Approach_for_UAV_Path_Planning_in_Dynamic_Environments)

### Implicit Step Rewards for Agentic RL (iStar)
* **Authors:** Jin et al.
* **Year:** 2025
* **Summary:** Introduces a general credit-assignment strategy for LLM agents that learns step-wise reward functions from trajectory preferences.
* **Link:** [View Paper](https://arxiv.org/abs/2502.04856)

### Process Reinforcement through Implicit Rewards (PRIME)
* **Authors:** Ganqu Cui et al.
* **Year:** 2025
* **Summary:** Enables online updates for process reward models using only final outcome labels, significantly increasing training efficiency for complex reasoning.
* **Link:** [View Paper](https://arxiv.org/abs/2502.01456)
